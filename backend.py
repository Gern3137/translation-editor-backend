from fastapi import FastAPI, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List
from openai import OpenAI
from dotenv import load_dotenv
import fitz  # PyMuPDF
import os
import json
import re

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI()

# Set allowed CORS origins based on environment
ENV = os.getenv("ENVIRONMENT", "development")
if ENV == "production":
    allowed_origins = ["https://translation-editor-frontend.vercel.app"]
else:
    allowed_origins = [
        "http://localhost:3000",
        "http://127.0.0.1:3000"
    ]

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AlignedTranslation(BaseModel):
    original: str
    translated: str

class TranslationResponse(BaseModel):
    pairs: List[AlignedTranslation]

DEFAULT_USER_PROMPT = """
ä»¥ä¸‹ã®è‹±èªã®æ–‡ç« ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚ç¿»è¨³ã«ã‚ãŸã£ã¦ã¯ã€æ¬¡ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
å†…å®¹ã®å¿ å®Ÿæ€§ï¼šåŸæ–‡ã®æƒ…å ±ã‚„æ„å‘³ã‚’ä¸€åˆ‡å¤‰ãˆãšã€å–ã‚Šã“ã¼ã—ãŒãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
æ–‡è„ˆã®ç†è§£ï¼šæ–‡ç« å…¨ä½“ã®æµã‚Œã‚„èƒŒæ™¯ã‚’æ­£ç¢ºã«ç†è§£ã—ã€é©åˆ‡ãªè¨³èªã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®å†ç¾ï¼šè¨€è‘‰ã®å¾®å¦™ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚„æ„Ÿæƒ…ã€æ–‡åŒ–çš„ãªè¦ç´ ã‚’å¯èƒ½ãªé™ã‚Šæ—¥æœ¬èªã§å†ç¾ã—ã¦ãã ã•ã„ã€‚
è‡ªç„¶ãªæ—¥æœ¬èªè¡¨ç¾ï¼šç›´è¨³ã«ãªã‚‰ãªã„ã‚ˆã†ã«æ³¨æ„ã—ã€æ—¥æœ¬èªã¨ã—ã¦è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã«ä»•ä¸Šã’ã¦ãã ã•ã„ã€‚
å°‚é–€ç”¨èªã‚„å›ºæœ‰åè©ã®çµ±ä¸€æ€§ï¼šå°‚é–€ç”¨èªã‚„å›ºæœ‰åè©ãŒç¹°ã‚Šè¿”ã—å‡ºã¦ãã‚‹å ´åˆã€ä¸€è²«ã—ãŸè¨³èªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
ãƒˆãƒ¼ãƒ³ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã®ç¶­æŒï¼šåŸæ–‡ã®ãƒˆãƒ¼ãƒ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒ«ã€ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒãƒ«ã€ãƒ¦ãƒ¼ãƒ¢ãƒ©ã‚¹ãªã©ï¼‰ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
æ–‡æ³•ã¨å¥èª­ç‚¹ã®æ­£ç¢ºã•ï¼šæ—¥æœ¬èªã®æ–‡æ³•è¦å‰‡ã‚„å¥èª­ç‚¹ã®ä½¿ã„æ–¹ã«å¾“ã£ã¦ãã ã•ã„ã€‚
æ–‡åŒ–çš„èƒŒæ™¯ã®è€ƒæ…®ï¼šæ–‡åŒ–çš„ãªèƒŒæ™¯ã‚„æ…£ç”¨è¡¨ç¾ã‚’æ—¥æœ¬ã®èª­è€…ãŒç†è§£ã—ã‚„ã™ã„å½¢ã§ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
èª­è€…ã®è¦–ç‚¹ï¼šæ—¥æœ¬èªè©±è€…ãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’å¿ƒãŒã‘ã€å¿…è¦ã«å¿œã˜ã¦è£œè¶³èª¬æ˜ã‚’åŠ ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
ä¸æ˜ãªç®‡æ‰€ã®å‡¦ç†ï¼šæ›–æ˜§ãªè¡¨ç¾ã‚„ç†è§£ãŒé›£ã—ã„éƒ¨åˆ†ãŒã‚ã‚Œã°ã€é©åˆ‡ã«è§£é‡ˆã—ã¦ç¿»è¨³ã™ã‚‹ã‹ã€æ³¨é‡ˆã‚’åŠ ãˆã¦ãã ã•ã„ã€‚
ä»¥ä¸Šã®ç‚¹
"""

SYSTEM_PROMPT = """
You are an experienced English-to-Japanese translator.

System Instructions (must be strictly followed):
- Translate one English sentence into exactly one Japanese sentence.
- Do NOT split or merge English sentences.
- Translate '.' and '!' as 'ã€‚'
- Do NOT use 'ã€‚' for other punctuation like ':', '(', etc.
- Return ONLY a valid JSON array like:
[{"original": "Sentence.", "translated": "æ–‡ã€‚"}]
"""

def clean_text(raw_text):
    lines = raw_text.splitlines()
    cleaned = []
    for line in lines:
        line = line.strip()
        if not line or line.isdigit():
            continue
        if line.isupper() and len(line.split()) < 6:
            continue
        if len(line) <= 2 and all(char in "'\"â€œâ€â€™â€˜-â€“â€”" for char in line):
            continue
        cleaned.append(line)
    return " ".join(cleaned)

def preprocess_sentences(text):
    text = re.sub(r'(\w+)-\s+(\w+)', r'\1\2', text)
    text = re.sub(r'\s*\n\s*', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def split_sentences(text):
    return re.findall(r"[^\u3002\uff01\uff1f.?!]+[\u3002\uff01\uff1f.?!]", text)

def build_prompt(sentences, user_prompt):
    joined = "\n".join(f"{i+1}. {s}" for i, s in enumerate(sentences))
    return f"""
User Style Guidance (follow if it does not conflict with the system instructions):
{user_prompt.strip()}

Translate the following English sentences into Japanese:
{joined}

Return ONLY the JSON array in this format:
[{{"original": "...", "translated": "..."}}]
""".strip()

def filter_skip_words(sentences, skip_words_str):
    skip_lines = [w.strip() for w in skip_words_str.splitlines() if w.strip()]
    if not skip_lines:
        return sentences
    return [s for s in sentences if not any(skip_word in s for skip_word in skip_lines)]

@app.post("/upload/", response_model=TranslationResponse)
async def upload_file(
    file: UploadFile,
user_prompt: str = Form(default=None),
skip_words: str = Form(default=None)

):
    if not user_prompt.strip():
        user_prompt = DEFAULT_USER_PROMPT

    if file.content_type != "application/pdf":
        raise HTTPException(status_code=400, detail="Only PDF files are supported.")

    content = await file.read()
    doc = fitz.open(stream=content, filetype="pdf")

    blocks = []
    for page in doc:
        for b in page.get_text("blocks"):
            blocks.append((page.number, b[1], b[4]))
    blocks = sorted(blocks, key=lambda b: (b[0], b[1]))
    raw_text = "\n".join(b[2] for b in blocks)

    lines = raw_text.splitlines()
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if all(c in "'\"â€œâ€â€™â€˜-â€“â€”*â€¢" for c in line.strip()):
            continue
        cleaned_lines.append(line)
    cleaned = "\n".join(cleaned_lines)

    preprocessed = preprocess_sentences(cleaned)
    sentences = split_sentences(preprocessed)
    sentences = filter_skip_words(sentences, skip_words)

    print(f"ğŸ“„ Total sentences extracted: {len(sentences)}")

    CHUNK_SIZE = 30
    all_pairs = []

    try:
        for i in range(0, len(sentences), CHUNK_SIZE):
            chunk = sentences[i:i + CHUNK_SIZE]
            prompt = build_prompt(chunk, user_prompt)

            print(f"ğŸ§© Sending chunk {i // CHUNK_SIZE + 1} with {len(chunk)} sentences...")

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )

            output = response.choices[0].message.content.strip()
            print("ğŸ“¥ GPT raw output (start):", output[:300])

            start = output.find("[")
            end = output.rfind("]")
            if start == -1 or end == -1:
                print("âŒ GPT returned invalid JSON")
                print("âŒ Full output:", output)
                raise ValueError("No JSON array found in GPT response.")

            json_str = output[start:end+1]
            raw_pairs = json.loads(json_str)

            pairs = [AlignedTranslation(**p) for p in raw_pairs]
            all_pairs.extend(pairs)

        print(f"âœ… Finished! Translated {len(all_pairs)} sentence pairs.")
        return {"pairs": all_pairs}

    except Exception as e:
        print("ğŸ”¥ Upload endpoint error:", str(e))
        raise HTTPException(status_code=500, detail=f"Upload translation failed: {str(e)}")